{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anish Mulay\\AppData\\Local\\Temp\\ipykernel_16624\\2379040384.py:44: RuntimeWarning: overflow encountered in exp\n",
      "  sf = 1/(1+ np.exp(-self.DecisionBoundary(w)))\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 105\u001b[0m\n\u001b[0;32m     96\u001b[0m obj\u001b[39m.\u001b[39mDecisionBoundary(np\u001b[39m.\u001b[39marray([\u001b[39m1\u001b[39m,\u001b[39m1\u001b[39m,\u001b[39m1\u001b[39m,\u001b[39m1\u001b[39m]))\n\u001b[0;32m     97\u001b[0m \u001b[39m# sigmoid_function = obj.SigmoidFunction()\u001b[39;00m\n\u001b[0;32m     98\u001b[0m \u001b[39m# print(\"sigmoid function: \\n\",sigmoid_function)\u001b[39;00m\n\u001b[0;32m     99\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[39m# gradient = obj.gradCost()\u001b[39;00m\n\u001b[0;32m    103\u001b[0m \u001b[39m# print(\"gradient\", gradient)\u001b[39;00m\n\u001b[1;32m--> 105\u001b[0m obj\u001b[39m.\u001b[39;49msgd_const_alpha(\u001b[39m0.1\u001b[39;49m)\n\u001b[0;32m    106\u001b[0m obj\u001b[39m.\u001b[39mMSE()\n",
      "Cell \u001b[1;32mIn[3], line 80\u001b[0m, in \u001b[0;36mPolynomialRegression.sgd_const_alpha\u001b[1;34m(self, alpha)\u001b[0m\n\u001b[0;32m     78\u001b[0m i\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m\n\u001b[0;32m     79\u001b[0m \u001b[39mwhile\u001b[39;00m i \u001b[39m<\u001b[39m \u001b[39m10000\u001b[39m:\n\u001b[1;32m---> 80\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstarting_point2 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnew_point(starting_point \u001b[39m=\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstarting_point,alpha \u001b[39m=\u001b[39;49m alpha)\n\u001b[0;32m     81\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstarting_point \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstarting_point2\n\u001b[0;32m     82\u001b[0m     i\u001b[39m+\u001b[39m\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m\n",
      "Cell \u001b[1;32mIn[3], line 73\u001b[0m, in \u001b[0;36mPolynomialRegression.new_point\u001b[1;34m(self, starting_point, alpha)\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mnew_point\u001b[39m(\u001b[39mself\u001b[39m,starting_point,alpha):\n\u001b[0;32m     72\u001b[0m     \u001b[39m# print(\"gradient: \",self.gradCost(starting_point))\u001b[39;00m\n\u001b[1;32m---> 73\u001b[0m     \u001b[39mreturn\u001b[39;00m(starting_point \u001b[39m-\u001b[39m alpha \u001b[39m*\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgradCost(starting_point)\u001b[39m.\u001b[39mtranspose())\n",
      "Cell \u001b[1;32mIn[3], line 66\u001b[0m, in \u001b[0;36mPolynomialRegression.gradCost\u001b[1;34m(self, w)\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgradCost\u001b[39m(\u001b[39mself\u001b[39m,w):\n\u001b[0;32m     64\u001b[0m     \u001b[39m# print(\"x shape: \",self.x_train.transpose().shape)\u001b[39;00m\n\u001b[0;32m     65\u001b[0m     grad_j \u001b[39m=\u001b[39m ((\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mSigmoidFunction(w) \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39my_train)\u001b[39m.\u001b[39mtranspose())\u001b[39m*\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mx_train)\u001b[39m/\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mm\n\u001b[1;32m---> 66\u001b[0m     grad_j \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([np\u001b[39m.\u001b[39msum(row) \u001b[39mfor\u001b[39;00m row \u001b[39min\u001b[39;00m grad_j])\n\u001b[0;32m     67\u001b[0m     \u001b[39m# print(\"grad_j: \",grad_j.shape)\u001b[39;00m\n\u001b[0;32m     68\u001b[0m     \u001b[39m# print(\"grad_j: \\n\",grad_j)\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39mreturn\u001b[39;00m (grad_j)\n",
      "Cell \u001b[1;32mIn[3], line 66\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgradCost\u001b[39m(\u001b[39mself\u001b[39m,w):\n\u001b[0;32m     64\u001b[0m     \u001b[39m# print(\"x shape: \",self.x_train.transpose().shape)\u001b[39;00m\n\u001b[0;32m     65\u001b[0m     grad_j \u001b[39m=\u001b[39m ((\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mSigmoidFunction(w) \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39my_train)\u001b[39m.\u001b[39mtranspose())\u001b[39m*\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mx_train)\u001b[39m/\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mm\n\u001b[1;32m---> 66\u001b[0m     grad_j \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([np\u001b[39m.\u001b[39msum(row) \u001b[39mfor\u001b[39;00m row \u001b[39min\u001b[39;00m grad_j])\n\u001b[0;32m     67\u001b[0m     \u001b[39m# print(\"grad_j: \",grad_j.shape)\u001b[39;00m\n\u001b[0;32m     68\u001b[0m     \u001b[39m# print(\"grad_j: \\n\",grad_j)\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39mreturn\u001b[39;00m (grad_j)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_ds = open(\"C:/Users/Anish Mulay/Documents/2nd Year/ED5340 - DS/LAB/LAB10_ED21B011- PART2/Train_dataset.csv\")\n",
    "\n",
    "class PolynomialRegression:\n",
    "    def __init__(self,dataset,n):\n",
    "        self.df = pd.read_csv(dataset)\n",
    "        self.x_train_pd = self.df.iloc[:,0]\n",
    "        # self.x_train_pd = np.append(self.x_train_pd,df.iloc[:,1])\n",
    "        \n",
    "        self.x_train = np.array([self.x_train_pd.to_numpy()])\n",
    "        self.x_train = np.insert(self.x_train,[0],[[1],],axis = 0)\n",
    "        self.x_train = np.insert(self.x_train,[2],[(self.x_train[1])**2],axis = 0)\n",
    "        self.x_train = np.insert(self.x_train,[2],[(self.x_train[2])**2],axis = 0)\n",
    "        # self.x_train = np.append(self.x_train, [(df.iloc[:1]).to_numpy()])\n",
    "        self.y_train_pd = self.df.iloc[:,-1]\n",
    "        self.y_train = self.y_train_pd.to_numpy()\n",
    "        # print(\"x :\\n\",self.x_train)\n",
    "        # print(\"y: \\n\",self.y_train)\n",
    "\n",
    "        self.m = self.y_train.shape[0]\n",
    "        self.w_start = np.array([1]*n)\n",
    "        self.starting_point = self.w_start\n",
    "\n",
    "    def Hypothesis(self,w):\n",
    "        \n",
    "        self.decision_boundary = (w*self.x_train.transpose())\n",
    "        \n",
    "        self.decision_boundary = np.array([np.sum(row) for row in self.decision_boundary])\n",
    "        shape = w.shape\n",
    "        # print(shape)\n",
    "        # print(\"decision boundary: \\n\",self.decision_boundary)\n",
    "        # print(self.decision_boundary)\n",
    "        return (self.decision_boundary)\n",
    "    \n",
    "    def PlotDecisionBoundary(self,w):\n",
    "        x1 = self.x_train[1]\n",
    "        x2 = ((-w[:2])*self.x_train[:2].transpose())/w[2]\n",
    "        \n",
    "        x2 = np.array([np.sum(row) for row in x2])\n",
    "        \n",
    "        plt.plot(x1,x2)\n",
    "        # print(x2)\n",
    "    \n",
    "    def SigmoidFunction(self,w):\n",
    "        sf = 1/(1+ np.exp(-self.Hypothesis(w)))\n",
    "        # print(sf.transpose().shape)\n",
    "        return (sf)\n",
    "    \n",
    "    def Plot_x1_x2(self,):\n",
    "        \n",
    "        # plt.scatter(x1,x2,color = \"red\")\n",
    "        plt.scatter(self.df[self.df.label==0].x1, self.df[self.df.label==0].x2, color = \"blue\")\n",
    "        plt.scatter(self.df[self.df.label==1].x1, self.df[self.df.label==1].x2, color = \"red\")\n",
    "        # plt.plot(*self.decision_boundary)\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "    def CostFunction(self,point,l):\n",
    "        j = (self.Hypothesis(point) - self.y_train)**2/ (2*self.m)\n",
    "        j = np.sum(j)\n",
    "        j += l * np.array([np.sum(row) for row in self.point])/(2*self.m)\n",
    "        print(\"cost: \\n\",j)\n",
    "    \n",
    "    def gradCost(self,w):\n",
    "        # print(\"x shape: \",self.x_train.transpose().shape)\n",
    "        grad_j = ((self.Hypothesis(w) - self.y_train).transpose())*(self.x_train)/self.m\n",
    "        grad_j = np.array([np.sum(row) for row in grad_j])\n",
    "        # print(\"grad_j: \",grad_j.shape)\n",
    "        # print(\"grad_j: \\n\",grad_j)\n",
    "        return (grad_j)\n",
    "\n",
    "    def new_point(self,starting_point,alpha):\n",
    "        # print(\"gradient: \",self.gradCost(starting_point))\n",
    "        return(starting_point - alpha * self.gradCost(starting_point).transpose())\n",
    "    \n",
    "    def sgd_const_alpha(self,alpha):\n",
    "        new_Ws = []\n",
    "        i=0\n",
    "        while i < 10000:\n",
    "            self.starting_point2 = self.new_point(starting_point = self.starting_point,alpha = alpha)\n",
    "            self.starting_point = self.starting_point2\n",
    "            i+=1\n",
    "        \n",
    "        self.final_w = self.starting_point2\n",
    "        print(\"final w: \\n\",self.starting_point2)\n",
    "        self.PlotDecisionBoundary(w = self.final_w)\n",
    "    \n",
    "    def MSE(self):\n",
    "        error = (self.SigmoidFunction(w = self.final_w) - self.y_train)**2/(2*self.m)\n",
    "        error = np.sum(error)\n",
    "        print(\"Mean squared error: \",error)\n",
    "\n",
    "\n",
    "\n",
    "obj = PolynomialRegression(train_ds,4)\n",
    "obj.Hypothesis(np.array([1,1,1,1]))\n",
    "# sigmoid_function = obj.SigmoidFunction()\n",
    "# print(\"sigmoid function: \\n\",sigmoid_function)\n",
    "\n",
    "# obj.Plot_x1_x2()\n",
    "# obj.CostFunction()\n",
    "# gradient = obj.gradCost()\n",
    "# print(\"gradient\", gradient)\n",
    "\n",
    "obj.sgd_const_alpha(0.1)\n",
    "obj.MSE()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
